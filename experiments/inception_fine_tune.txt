train_top_classifier --name 'stable' --lr 0.0001 --epochs 1000 --batch_size 1024 --l2_reg 0 --dropout_p 0.5 --save_model True
train_top_classifier --name 'final' --lr 0.0001 --epochs 1000 --batch_size 1024 --l2_reg 0 --dropout_p 0.5 --save_model True

0.1 VAL DATA CROPPED WITH ADDITIONAL
------------------------------------
GROUP 0
fine_tune --name 'stable' --name_ext 'frozen_280_dropout_0_5' --lr 1e-5 --reduce_lr_factor 0.1 --reduce_lr_patience 100 --epochs 100 --batch_size 256 --l2_reg 0 --dropout_p 0.5 --num_freeze_layers 280
Epoch 18 - loss: 0.4608 - val_loss: 0.7203

GROUP 1
fine_tune --name 'stable' --name_ext 'frozen_270_dropout_0_5' --lr 1e-5 --reduce_lr_factor 0.1 --reduce_lr_patience 100 --epochs 100 --batch_size 256 --l2_reg 0 --dropout_p 0.5 --num_freeze_layers 270
Epoch 18 - loss: 0.4567 - val_loss: 0.7166

GROUP 2
fine_tune --name 'stable' --name_ext 'frozen_260_dropout_0_5' --lr 1e-5 --reduce_lr_factor 0.1 --reduce_lr_patience 100 --epochs 100 --batch_size 256 --l2_reg 0 --dropout_p 0.5 --num_freeze_layers 260
Epoch 18 - loss: 0.4646 - val_loss: 0.7440

GROUP 3
fine_tune --name 'stable' --name_ext 'frozen_250_dropout_0_5' --lr 1e-5 --reduce_lr_factor 0.1 --reduce_lr_patience 100 --epochs 100 --batch_size 256 --l2_reg 0 --dropout_p 0.5 --num_freeze_layers 250
Epoch 17 - loss: 0.4869 - val_loss: 0.7473

FINAL
-----
GROUP 0
fine_tune --name 'final' --name_ext 'frozen_280_dropout_0_5' --lr 1e-5 --reduce_lr_factor 0.1 --reduce_lr_patience 100 --epochs 18 --batch_size 256 --l2_reg 0 --dropout_p 0.5 --num_freeze_layers 280 --save_best_only False
Epoch 18 - loss: 0.5135 - val_loss: 0.6969

GROUP 1
fine_tune --name 'final' --name_ext 'frozen_270_dropout_0_5' --lr 1e-5 --reduce_lr_factor 0.1 --reduce_lr_patience 100 --epochs 18 --batch_size 256 --l2_reg 0 --dropout_p 0.5 --num_freeze_layers 270 --save_best_only False
Epoch 18 - loss: 0.5016 - val_loss: 0.7671

GROUP 2
fine_tune --name 'final' --name_ext 'frozen_260_dropout_0_5' --lr 1e-5 --reduce_lr_factor 0.1 --reduce_lr_patience 100 --epochs 18 --batch_size 256 --l2_reg 0 --dropout_p 0.5 --num_freeze_layers 260 --save_best_only False
Epoch 18 - loss: 0.5074 - val_loss: 0.7685

GROUP 3
fine_tune --name 'final' --name_ext 'frozen_250_dropout_0_5' --lr 1e-5 --reduce_lr_factor 0.1 --reduce_lr_patience 100 --epochs 17 --batch_size 256 --l2_reg 0 --dropout_p 0.5 --num_freeze_layers 250 --save_best_only False
Epoch 17 - loss: 0.5323 - val_loss: 0.7439
