train_top_classifier --name 'stable' --lr 0.0001 --epochs 1000 --batch_size 1024 --l2_reg 0 --dropout_p 0.5 --save_model True
train_top_classifier --name 'final' --lr 0.0001 --epochs 1000 --batch_size 1024 --l2_reg 0 --dropout_p 0.5 --save_model True

0.1 VAL DATA CROPPED WITH ADDITIONAL
------------------------------------
GROUP 0
fine_tune --name 'stable' --name_ext 'frozen_86_dropout_0_2' --lr 1e-5 --reduce_lr_factor 0.1 --reduce_lr_patience 50 --epochs 50 --batch_size 256 --l2_reg 0 --dropout_p 0.2 --num_freeze_layers 86
Epoch 24 - loss: 0.4228 - val_loss: 0.7288 (0.71206 public score)

GROUP 1
fine_tune --name 'stable' --name_ext 'frozen_96_dropout_0_6' --lr 1e-5 --reduce_lr_factor 0.1 --reduce_lr_patience 30 --epochs 30 --batch_size 256 --l2_reg 0 --dropout_p 0.6 --num_freeze_layers 96
Epoch 26 - loss: 0.4987 - val_loss: 0.7383

GROUP 2
fine_tune --name 'stable' --name_ext 'frozen_86_dropout_0_6' --lr 1e-5 --reduce_lr_factor 0.1 --reduce_lr_patience 50 --epochs 50 --batch_size 256 --l2_reg 0 --dropout_p 0.6 --num_freeze_layers 86
Epoch 27- loss: 0.4783 - val_loss: 0.7386

GROUP 3
fine_tune --name 'stable' --name_ext 'frozen_86_dropout_0_5' --lr 1e-5 --reduce_lr_factor 0.1 --reduce_lr_patience 50 --epochs 50 --batch_size 256 --l2_reg 0 --dropout_p 0.5 --num_freeze_layers 86
Epoch 24 - loss: 0.4990 - val_loss: 0.7520 (0.69868 public score)

FINAL
-----
GROUP 0
fine_tune --name 'final' --name_ext 'frozen_86_dropout_0_2' --lr 1e-5 --reduce_lr_factor 0.1 --reduce_lr_patience 50 --epochs 24 --batch_size 256 --l2_reg 0 --dropout_p 0.2 --num_freeze_layers 86 --save_best_only False
todo a

GROUP 1
fine_tune --name 'final' --name_ext 'frozen_96_dropout_0_6' --lr 1e-5 --reduce_lr_factor 0.1 --reduce_lr_patience 30 --epochs 26 --batch_size 256 --l2_reg 0 --dropout_p 0.6 --num_freeze_layers 96 --save_best_only False
todo b

GROUP 2
fine_tune --name 'final' --name_ext 'frozen_86_dropout_0_6' --lr 1e-5 --reduce_lr_factor 0.1 --reduce_lr_patience 50 --epochs 27 --batch_size 256 --l2_reg 0 --dropout_p 0.6 --num_freeze_layers 86 --save_best_only False
todo c

GROUP 3
fine_tune --name 'final' --name_ext 'frozen_86_dropout_0_5' --lr 1e-5 --reduce_lr_factor 0.1 --reduce_lr_patience 50 --epochs 24 --batch_size 256 --l2_reg 0 --dropout_p 0.5 --num_freeze_layers 86 --save_best_only False
todo d
